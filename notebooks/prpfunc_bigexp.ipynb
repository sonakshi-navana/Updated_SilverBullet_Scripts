{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder to find .wav files\n",
    "valdata_folder=\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/\"\n",
    "#Spk2utt mapping path\n",
    "valspk2utt =\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/450-speakers/utt2spk\"\n",
    "#wav.scp path\n",
    "valwavscp=\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/450-speakers/wav.scp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unval file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder to find .wav files\n",
    "data_folder=\"/mnt/datadrive/datasets/spkveri/mrt1/btch03-no-empty/\"\n",
    "#Spk2utt mapping path\n",
    "spk2utt =\"/mnt/datadrive/datasets/spkveri/mrt1/btch03-no-empty/utt2spk\"\n",
    "#wav.scp path\n",
    "wavscp=\"/mnt/datadrive/datasets/spkveri/mrt1/btch03-no-empty/wav.scp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to save the preprocessed data\n",
    "output_folder=\"/mnt/training/silverbullet-testenv/test-02-bigexp/save/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srini/.conda/envs/speechbrain/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_test (test_df: pd.DataFrame, output_folder):\n",
    "    \n",
    "    #randomise the columns\n",
    "   \n",
    "    \n",
    "    values = test_df['wav'].tolist()\n",
    "    random.shuffle(values)\n",
    "    test_df['shuffled_column'] = values\n",
    "\n",
    "    list2=test_df[\"shuffled_column\"].iloc[0]\n",
    "    #print(str(list2.split(\"/\")[8]))\n",
    "    \n",
    "    #fn to set the labels\n",
    "    def get_label(list1,list2):\n",
    "        uniq_id= list1\n",
    "        shuf_col = list2\n",
    "        label=\"\"\n",
    "        if (str(list1.split(\"_\")[0]) == str(list2.split(\"/\")[4])):\n",
    "            label = 1\n",
    "            #print(str(list1.split(\"_\")[0]),str(list2.split(\"/\")[8]),label)\n",
    "        else:\n",
    "            label = 0\n",
    "            #print(str(list1.split(\"_\")[0]),str(list2.split(\"/\")[8]),label)\n",
    "        return(int(label))\n",
    "\n",
    "\n",
    "    test_df[\"label\"] = test_df.apply(lambda x: get_label(x[\"ID\"], x[\"shuffled_column\"]), axis=1)\n",
    "    \n",
    "    test_df=test_df.drop(columns=[\"spk_id\",\"ID\"])\n",
    "    \n",
    "    veri_test = test_df.reindex(columns=['label', 'wav', 'shuffled_column'])\n",
    "    \n",
    "    #save the data frame as csv \n",
    "    print(len(veri_test))\n",
    "    print(\"Saving veri_test\")\n",
    "    veri_test.to_csv(output_folder+\"veri_test.txt\", sep=\" \", index=False, header=False)\n",
    "    print(\"Saved veri_test\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_prep (data_folder, df: pd.DataFrame):\n",
    "    \n",
    "    df[\"start\"]=\" \"\n",
    "    \n",
    "    groups = df.groupby(df['ID'].apply(lambda x: x.split('_')[0]))\n",
    "    \n",
    "    output = []\n",
    "    for spk, group in groups:\n",
    "        for index, row in group.iterrows():\n",
    "            id = row['ID'].split('_')[1]\n",
    "            wav = data_folder +spk+ \"/\" + id +  \".wav\"\n",
    "            #print(wav)\n",
    "\n",
    "    \n",
    "            signal, fs = torchaudio.load(wav)\n",
    "            signal = signal.squeeze(0)\n",
    "            audio_duration = signal.shape[0] / 16000\n",
    "            start_sample = 0\n",
    "            stop_sample = signal.shape[0]\n",
    "            stop_sample= int(stop_sample)\n",
    "            #print(stop_sample)\n",
    "\n",
    "            df.loc[index, 'start'] = start_sample\n",
    "            df.loc[index, \"stop\"] = stop_sample\n",
    "            df.loc[index, \"duration\"] = audio_duration \n",
    " \n",
    "            \n",
    "    df['stop'] = df['stop'].astype(int)\n",
    "    \n",
    "    df_f = df.reindex(columns=['ID', 'duration', 'wav', \"start\",\"stop\",\"spk_id\"])\n",
    "\n",
    "    #print(\"num_frames\")\n",
    "    #num_frames=df['stop']-df['start']\n",
    "    #print(num_frames)\n",
    "    \n",
    "    return df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "    spk_id_groups = df.groupby('spk_id')\n",
    "    final_train = pd.DataFrame(columns=df.columns)\n",
    "    final_dev = pd.DataFrame(columns=df.columns)\n",
    "    final_test = pd.DataFrame(columns=df.columns)\n",
    "    final_enrol= pd.DataFrame(columns=df.columns)\n",
    "    for name, group in spk_id_groups:\n",
    "        group_size = group.shape[0]\n",
    "        train_size = int(group_size * 0.5)\n",
    "        dev_size = int(group_size * 0.2)\n",
    "        test_size = int(group_size * 0.3)\n",
    "\n",
    "        train_df = group.iloc[:train_size]\n",
    "        test_df = group.iloc[train_size:train_size+test_size]\n",
    "        dev_df = group.iloc[train_size+test_size:]\n",
    "\n",
    "        final_train = final_train.append(train_df)\n",
    "        final_dev = final_dev.append(dev_df)\n",
    "        final_test = final_test.append(test_df)\n",
    "        final_enrol= final_enrol.append(test_df)\n",
    "    final_train.reset_index(drop=True, inplace=True)\n",
    "    final_dev.reset_index(drop=True, inplace=True)\n",
    "    final_test.reset_index(drop=True, inplace=True)\n",
    "    final_enrol.reset_index(drop=True, inplace=True)\n",
    "    return final_train,final_dev,final_test,final_enrol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - n*20 validated speakers and get val embeddings for the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(spk2utt,wavscp,data_folder, output_folder):\n",
    "\n",
    "    #Make the main dataframe\n",
    "    \n",
    "    #spk2utt prep\n",
    "    d1=pd.read_csv(spk2utt)\n",
    "    d1.columns= [\"col1\"]\n",
    "    d1[['ID', 'spk_id']] = d1['col1'].str.split(' ', expand=True)\n",
    "    d1 = d1.drop(columns=[\"col1\"])\n",
    "    \n",
    "    #wav.scp prep\n",
    "    d2=pd.read_csv(wavscp)\n",
    "    d2.columns= [\"col1\"]\n",
    "    d2[['ID', 'wav']] = d2['col1'].str.split(' ', expand=True)\n",
    "    d2 = d2.drop(columns=[\"col1\"])\n",
    "    \n",
    "    #main df \n",
    "    d= pd.merge(d1, d2, on=\"ID\")\n",
    "    #print(d.head())\n",
    "    \n",
    "    #dealing with missing values/ changing path names in csv to actual path \n",
    "    d['wav'] = d['wav'].apply(lambda x: str(x).replace( '/home/sai/work/silver-bullet/batch-02/', '/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/'))\n",
    "    print(\"Length of d\",len(d))\n",
    "    mask = d[\"wav\"].isin([\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783193/281474985386592.wav\",\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783193/281474985386582.wav\", \"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783193/281474985386570.wav\",\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783193/281474985386581.wav\",\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783114/281474985436102.wav\",\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16794090/281474989055448.wav\"])\n",
    "    d = d[~mask]\n",
    "    d['wav'] = d['wav'].apply(lambda x: str(x).replace('/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/',\" /mnt/datadrive/datasets/spkveri/mrt1/btch03-no-empty/\"))\n",
    "    print(\"Length of new d\",len(d)) \n",
    "    print(\"Made main data frame\")\n",
    "\n",
    "    # Get the unique id values\n",
    "    unique_ids = d['spk_id'].unique()\n",
    "    print(len(unique_ids))\n",
    "    \n",
    "\n",
    "    # Select the first n unique id values\n",
    "    selected_ids = unique_ids[0:3]\n",
    "    print(len(selected_ids))\n",
    "    #print(selected_ids==\"16783193\")\n",
    "\n",
    "    # Filter the DataFrame to select only rows with the selected id values\n",
    "    train_selected_rows = d[d['spk_id'].isin(selected_ids)]\n",
    "\n",
    "    #print(train_selected_rows)\n",
    "    print(len(train_selected_rows))\n",
    "    print(\"save the list\")\n",
    "    train_selected_rows.to_csv(output_folder+\"train_selected_rows.csv\", index= False)\n",
    "    print(\"saved the list\")\n",
    "    #get train.csv now \n",
    "\n",
    "    #Prep TRAIN csv file - use for benchmarking\n",
    "    print(\"start making the csv files\")\n",
    "    print(\"Saving train.csv\")\n",
    "    traindf=csv_prep(data_folder,train_selected_rows)\n",
    "    traindf.to_csv(output_folder+\"train.csv\", index= False)\n",
    "    print(\"Saved train.csv\")\n",
    "\n",
    "    #Prep VAL_EMB.CSV files (SAME THING AS TRAIN.CSV) - but use for emb generation\n",
    "    print(\"start making the csv files\")\n",
    "    print(\"Saving val_emb.csv\")\n",
    "    traindf=csv_prep(data_folder,train_selected_rows)\n",
    "    traindf.to_csv(output_folder+\"val_emb.csv\", index= False)\n",
    "    print(\"Saved val_emb.csv\")\n",
    "\n",
    "    print(\"Done train/val_emb preprocessing!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of d 11322\n",
      "Length of new d 11316\n",
      "Made main data frame\n",
      "455\n",
      "3\n",
      "74\n",
      "save the list\n",
      "saved the list\n",
      "start making the csv files\n",
      "Saving train.csv\n",
      "Saved train.csv\n",
      "start making the csv files\n",
      "Saving val_emb.csv\n",
      "Saved val_emb.csv\n",
      "Done train/val_emb preprocessing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3916482/318978911.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"start\"]=\" \"\n",
      "/tmp/ipykernel_3916482/318978911.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[index, 'start'] = start_sample\n",
      "/tmp/ipykernel_3916482/318978911.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[index, \"stop\"] = stop_sample\n",
      "/tmp/ipykernel_3916482/318978911.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[index, \"duration\"] = audio_duration\n",
      "/tmp/ipykernel_3916482/318978911.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['stop'] = df['stop'].astype(int)\n",
      "/tmp/ipykernel_3916482/318978911.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"start\"]=\" \"\n",
      "/tmp/ipykernel_3916482/318978911.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['stop'] = df['stop'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "train(valspk2utt,valwavscp,valdata_folder,output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test - Out of unvalidated 500 test random 10 out of 500 unval - 20val = 480 utterances per speaker \n",
    "Generate unval embeddings for n*480 speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(spk2utt,wavscp,data_folder, output_folder):\n",
    "    #Make the main dataframe\n",
    "    \n",
    "    #spk2utt prep\n",
    "    d1=pd.read_csv(spk2utt)\n",
    "    d1.columns= [\"col1\"]\n",
    "    d1[['ID', 'spk_id']] = d1['col1'].str.split(' ', expand=True)\n",
    "    d1 = d1.drop(columns=[\"col1\"])\n",
    "    \n",
    "    #wav.scp prep\n",
    "    d2=pd.read_csv(wavscp)\n",
    "    d2.columns= [\"col1\"]\n",
    "    d2[['ID', 'wav']] = d2['col1'].str.split(' ', expand=True)\n",
    "    d2 = d2.drop(columns=[\"col1\"])\n",
    "    \n",
    "    #main df \n",
    "    d= pd.merge(d1, d2, on=\"ID\")\n",
    "    print(d.head())\n",
    "\n",
    "    d['wav'] = d['wav'].apply(lambda x: str(x).replace( '/home/shreya/btch03-no-empty/', ' /mnt/datadrive/datasets/spkveri/mrt1/btch03-no-empty/'))\n",
    "    print(\"Length of d\",len(d))\n",
    "    #mask = d[\"wav\"].isin([\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783193/281474985386592.wav\",\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783193/281474985386582.wav\", \"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783193/281474985386570.wav\",\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783193/281474985386581.wav\",\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16783114/281474985436102.wav\",\"/mnt/datadrive/datasets/spkveri/mrt1/spk450/wav/16794090/281474989055448.wav\"])\n",
    "    #d = d[~mask]\n",
    "    #print(\"Length of new d\",len(d))\n",
    "    #print(d)\n",
    "\n",
    "    #test - RANDOM 10 UNVAL\n",
    "\n",
    "    #val samples 3*20\n",
    "    #Change path to wherever the train_selected_rows.csv obtained from the previous train fn is \n",
    "    # <output_folder>+train_selected_rows.csv\n",
    "    filtered_df=pd.read_csv(output_folder+\"train_selected_rows.csv\")\n",
    "    print(len(filtered_df))\n",
    "    #print(filtered_df.head())\n",
    "\n",
    "    #Unval 500-20= 480 \n",
    "    #t = pd.DataFrame()t = d[~d.isin(filtered_df)]print(t.head())print(len(t))\n",
    "    mask = d.index.isin(filtered_df.index)\n",
    "    temp_df= d[~mask]\n",
    "    temp_df= temp_df.reset_index(drop=True)\n",
    "    print(\"mask total -20val len\",len(temp_df))\n",
    "    #print(temp_df[\"spk_id\"]==\"16793950\")\n",
    "\n",
    "\n",
    "    #selected ids array\n",
    "    #selected_ids=[\"16793950\",\"16801899\",\"16794112\"]\n",
    "    selected_ids = filtered_df['spk_id'].unique()\n",
    "    str_array = [str(x) for x in selected_ids]\n",
    "    print(str_array)\n",
    "\n",
    "    #get n from 455 - THIS DF IS USED TO GET UNVAL_EMB.CSV \n",
    "    n_df= temp_df.loc[temp_df['spk_id'].isin(str_array)]\n",
    "    print(\"unval length of 3 speaker ids\", len(n_df))\n",
    "    #print(n_df)\n",
    "    print(\"save the list\")\n",
    "    n_df.to_csv(output_folder+\"test_selected_threeidsnoshuffling.csv\", index= False)\n",
    "    print(\"saved the list\")\n",
    "\n",
    "    #get 10 random from this list \n",
    "    # Group df by spk_id\n",
    "    grouped = n_df.groupby('spk_id')\n",
    "\n",
    "    #empty df to store the randomly selected rows\n",
    "    final_df = pd.DataFrame(columns=n_df.columns)\n",
    "\n",
    "    # Iterate over each group and select 10 random rows\n",
    "    for name, group in grouped:\n",
    "            final_df = final_df.append(group.sample(10))\n",
    "    #print(final_df.head())\n",
    "    print(\"len 10 from 3\",len(final_df))\n",
    "\n",
    "    #id= temp_df.loc[temp_df['spk_id']==\"16794112\"]\n",
    "    #print(id)\n",
    "    \n",
    "    #Prep veri_test\n",
    "    print(\"Start making veri_test\")\n",
    "    veri_test(final_df,output_folder)\n",
    "    print(\"Saved veri_test\")\n",
    "\n",
    "    #For experiment\n",
    "    print(\"Saving test.csv\")\n",
    "    testdf=csv_prep(data_folder,final_df)\n",
    "    testdf.to_csv(output_folder+\"test.csv\",index= False)\n",
    "    print(\"Saved test.csv\") \n",
    "\n",
    "    print(\"Saving enrol.csv\")\n",
    "    testdf=csv_prep(data_folder,final_df)\n",
    "    testdf.to_csv(output_folder+\"enrol.csv\",index= False)\n",
    "    print(\"Saved enrol.csv\")\n",
    "\n",
    "    #For embeddings\n",
    "    print(\"Saving unval_emb.csv\")\n",
    "    testdf=csv_prep(data_folder,n_df)\n",
    "    testdf.to_csv(output_folder+\"unval_emb.csv\",index= False)\n",
    "    print(\"Saved unval.csv\") \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ID    spk_id  \\\n",
      "0  16793950_281474988390972  16793950   \n",
      "1  16793950_281474988390973  16793950   \n",
      "2  16793950_281474988390974  16793950   \n",
      "3  16793950_281474988390975  16793950   \n",
      "4  16793950_281474988390976  16793950   \n",
      "\n",
      "                                                 wav  \n",
      "0  /home/shreya/btch03-no-empty/16793950/28147498...  \n",
      "1  /home/shreya/btch03-no-empty/16793950/28147498...  \n",
      "2  /home/shreya/btch03-no-empty/16793950/28147498...  \n",
      "3  /home/shreya/btch03-no-empty/16793950/28147498...  \n",
      "4  /home/shreya/btch03-no-empty/16793950/28147498...  \n",
      "Length of d 224000\n",
      "74\n",
      "mask total -20val len 223926\n",
      "['16793950', '16801899', '16794112']\n",
      "unval length of 3 speaker ids 1653\n",
      "save the list\n",
      "saved the list\n",
      "len 10 from 3 30\n",
      "Start making veri_test\n",
      "30\n",
      "Saving veri_test\n",
      "Saved veri_test\n",
      "Saved veri_test\n",
      "Saving test.csv\n",
      "Saved test.csv\n",
      "Saving enrol.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3916482/2825784369.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(group.sample(10))\n",
      "/tmp/ipykernel_3916482/2825784369.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(group.sample(10))\n",
      "/tmp/ipykernel_3916482/2825784369.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(group.sample(10))\n",
      "/tmp/ipykernel_3916482/318978911.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"start\"]=\" \"\n",
      "/tmp/ipykernel_3916482/318978911.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[index, 'start'] = start_sample\n",
      "/tmp/ipykernel_3916482/318978911.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[index, \"stop\"] = stop_sample\n",
      "/tmp/ipykernel_3916482/318978911.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[index, \"duration\"] = audio_duration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved enrol.csv\n",
      "Saving unval_emb.csv\n",
      "Saved unval.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3916482/318978911.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['stop'] = df['stop'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "test(spk2utt,wavscp,data_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preprocessing!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done preprocessing!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9225e3d79b2b84c801d9dab35dc3c6ff23ba8095ea0df61ec64ce9e876cee065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
